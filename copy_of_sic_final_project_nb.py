# -*- coding: utf-8 -*-
"""Copy of SIC_final_project nb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IWONjMsa8eXqc8ZJiV0q8OfL_atINpTF

<tr>
        <td width="15%">
        </td>
        <td>
            <div align="left">
                <font size=25px>
                    <b>House Price Prediction
                    </b>
                </font>
            </div>
        </td>
    </tr>

## Team 8 - Eshan Kushwah & Anushree M

## Problem Statement:
The objective of my dataset is to predcit the house prices using machine learning aims to develop a model that accurately estimates property values based on features like location, size, amenities, etc. The goal is to assist buyers, sellers, and real estate professionals in making informed decisions about pricing and investments.

## Data Definition:

train.csv - the training set   
test.csv - the test set                                
Data source - https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data


Attribute Information: It contains 1460 training data points and 80 features that might help us predict the selling price of a house.


**MSSubClass**: Identifies the type of dwelling involved in the sale.

        20	1-STORY 1946 & NEWER ALL STYLES
        30	1-STORY 1945 & OLDER
        40	1-STORY W/FINISHED ATTIC ALL AGES
        45	1-1/2 STORY - UNFINISHED ALL AGES
        50	1-1/2 STORY FINISHED ALL AGES
        60	2-STORY 1946 & NEWER
        70	2-STORY 1945 & OLDER
        75	2-1/2 STORY ALL AGES
        80	SPLIT OR MULTI-LEVEL
        85	SPLIT FOYER
        90	DUPLEX - ALL STYLES AND AGES
       120	1-STORY PUD (Planned Unit Development) - 1946 & NEWER
       150	1-1/2 STORY PUD - ALL AGES
       160	2-STORY PUD - 1946 & NEWER
       180	PUD - MULTILEVEL - INCL SPLIT LEV/FOYER
       190	2 FAMILY CONVERSION - ALL STYLES AND AGES

**MSZoning**: Identifies the general zoning classification of the sale.

       A	Agriculture
       C	Commercial
       FV	Floating Village Residential
       I	Industrial
       RH	Residential High Density
       RL	Residential Low Density
       RP	Residential Low Density Park
       RM	Residential Medium Density

**LotFrontage**: Linear feet of street connected to property

**LotArea**: Lot size in square feet

**Street**: Type of road access to property

       Grvl	Gravel
       Pave	Paved

**Alley**: Type of alley access to property

       Grvl	Gravel
       Pave	Paved
       NA 	No alley access

**LotShape**: General shape of property

       Reg	Regular
       IR1	Slightly irregular
       IR2	Moderately Irregular
       IR3	Irregular
       
**LandContour**: Flatness of the property

       Lvl	Near Flat/Level
       Bnk	Banked - Quick and significant rise from street grade to building
       HLS	Hillside - Significant slope from side to side
       Low	Depression

**Utilities**: Type of utilities available

       AllPub	All public Utilities (E,G,W,& S)
       NoSewr	Electricity, Gas, and Water (Septic Tank)
       NoSeWa	Electricity and Gas Only
       ELO	Electricity only

**LotConfig**: Lot configuration

       Inside	Inside lot
       Corner	Corner lot
       CulDSac	Cul-de-sac
       FR2	Frontage on 2 sides of property
       FR3	Frontage on 3 sides of property

**LandSlope**: Slope of property

       Gtl	Gentle slope
       Mod	Moderate Slope
       Sev	Severe Slope

**Neighborhood**: Physical locations within Ames city limits

       Blmngtn	Bloomington Heights
       Blueste	Bluestem
       BrDale	Briardale
       BrkSide	Brookside
       ClearCr	Clear Creek
       CollgCr	College Creek
       Crawfor	Crawford
       Edwards	Edwards
       Gilbert	Gilbert
       IDOTRR	Iowa DOT and Rail Road
       MeadowV	Meadow Village
       Mitchel	Mitchell
       Names	North Ames
       NoRidge	Northridge
       NPkVill	Northpark Villa
       NridgHt	Northridge Heights
       NWAmes	Northwest Ames
       OldTown	Old Town
       SWISU	South & West of Iowa State University
       Sawyer	Sawyer
       SawyerW	Sawyer West
       Somerst	Somerset
       StoneBr	Stone Brook
       Timber	Timberland
       Veenker	Veenker

**Condition1**: Proximity to various conditions

       Artery	Adjacent to arterial street
       Feedr	Adjacent to feeder street
       Norm	Normal
       RRNn	Within 200' of North-South Railroad
       RRAn	Adjacent to North-South Railroad
       PosN	Near positive off-site feature--park, greenbelt, etc.
       PosA	Adjacent to postive off-site feature
       RRNe	Within 200' of East-West Railroad
       RRAe	Adjacent to East-West Railroad

**Condition2**: Proximity to various conditions (if more than one is present)

       Artery	Adjacent to arterial street
       Feedr	Adjacent to feeder street
       Norm	Normal
       RRNn	Within 200' of North-South Railroad
       RRAn	Adjacent to North-South Railroad
       PosN	Near positive off-site feature--park, greenbelt, etc.
       PosA	Adjacent to postive off-site feature
       RRNe	Within 200' of East-West Railroad
       RRAe	Adjacent to East-West Railroad

**BldgType**: Type of dwelling

       1Fam	Single-family Detached
       2FmCon	Two-family Conversion; originally built as one-family dwelling
       Duplx	Duplex
       TwnhsE	Townhouse End Unit
       TwnhsI	Townhouse Inside Unit

**HouseStyle**: Style of dwelling

       1Story	One story
       1.5Fin	One and one-half story: 2nd level finished
       1.5Unf	One and one-half story: 2nd level unfinished
       2Story	Two story
       2.5Fin	Two and one-half story: 2nd level finished
       2.5Unf	Two and one-half story: 2nd level unfinished
       SFoyer	Split Foyer
       SLvl	Split Level

**OverallQual**: Rates the overall material and finish of the house

       10	Very Excellent
       9	Excellent
       8	Very Good
       7	Good
       6	Above Average
       5	Average
       4	Below Average
       3	Fair
       2	Poor
       1	Very Poor

**OverallCond**: Rates the overall condition of the house

       10	Very Excellent
       9	Excellent
       8	Very Good
       7	Good
       6	Above Average
       5	Average
       4	Below Average
       3	Fair
       2	Poor
       1	Very Poor

**YearBuilt**: Original construction date

**YearRemodAdd**: Remodel date (same as construction date if no remodeling or additions)

**RoofStyle**: Type of roof

       Flat	Flat
       Gable	Gable
       Gambrel	Gabrel (Barn)
       Hip	Hip
       Mansard	Mansard
       Shed	Shed

**RoofMatl**: Roof material

       ClyTile	Clay or Tile
       CompShg	Standard (Composite) Shingle
       Membran	Membrane
       Metal	Metal
       Roll	Roll
       Tar&Grv	Gravel & Tar
       WdShake	Wood Shakes
       WdShngl	Wood Shingles

**Exterior1st**: Exterior covering on house

       AsbShng	Asbestos Shingles
       AsphShn	Asphalt Shingles
       BrkComm	Brick Common
       BrkFace	Brick Face
       CBlock	Cinder Block
       CemntBd	Cement Board
       HdBoard	Hard Board
       ImStucc	Imitation Stucco
       MetalSd	Metal Siding
       Other	Other
       Plywood	Plywood
       PreCast	PreCast
       Stone	Stone
       Stucco	Stucco
       VinylSd	Vinyl Siding
       Wd Sdng	Wood Siding
       WdShing	Wood Shingles

**Exterior2nd**: Exterior covering on house (if more than one material)

       AsbShng	Asbestos Shingles
       AsphShn	Asphalt Shingles
       BrkComm	Brick Common
       BrkFace	Brick Face
       CBlock	Cinder Block
       CemntBd	Cement Board
       HdBoard	Hard Board
       ImStucc	Imitation Stucco
       MetalSd	Metal Siding
       Other	Other
       Plywood	Plywood
       PreCast	PreCast
       Stone	Stone
       Stucco	Stucco
       VinylSd	Vinyl Siding
       Wd Sdng	Wood Siding
       WdShing	Wood Shingles

**MasVnrType**: Masonry veneer type

       BrkCmn	Brick Common
       BrkFace	Brick Face
       CBlock	Cinder Block
       None	None
       Stone	Stone

**MasVnrArea**: Masonry veneer area in square feet

**ExterQual**: Evaluates the quality of the material on the exterior

       Ex	Excellent
       Gd	Good
       TA	Average/Typical
       Fa	Fair
       Po	Poor

**ExterCond**: Evaluates the present condition of the material on the exterior

       Ex	Excellent
       Gd	Good
       TA	Average/Typical
       Fa	Fair
       Po	Poor

**Foundation**: Type of foundation

       BrkTil	Brick & Tile
       CBlock	Cinder Block
       PConc	Poured Contrete
       Slab	Slab
       Stone	Stone
       Wood	Wood

**BsmtQual** Evaluates the height of the basement

       Ex	Excellent (100+ inches)
       Gd	Good (90-99 inches)
       TA	Typical (80-89 inches)
       Fa	Fair (70-79 inches)
       Po	Poor (<70 inches)
       NA	No Basement

**BsmtCond**: Evaluates the general condition of the basement

       Ex	Excellent
       Gd	Good
       TA	Typical - slight dampness allowed
       Fa	Fair - dampness or some cracking or settling
       Po	Poor - Severe cracking, settling, or wetness
       NA	No Basement

**BsmtExposure**: Refers to walkout or garden level walls

       Gd	Good Exposure
       Av	Average Exposure (split levels or foyers typically score average or above)
       Mn	Mimimum Exposure
       No	No Exposure
       NA	No Basement

**BsmtFinType1**: Rating of basement finished area

       GLQ	Good Living Quarters
       ALQ	Average Living Quarters
       BLQ	Below Average Living Quarters
       Rec	Average Rec Room
       LwQ	Low Quality
       Unf	Unfinshed
       NA	No Basement

**BsmtFinSF1**: Type 1 finished square feet

**BsmtFinType2**: Rating of basement finished area (if multiple types)

       GLQ	Good Living Quarters
       ALQ	Average Living Quarters
       BLQ	Below Average Living Quarters
       Rec	Average Rec Room
       LwQ	Low Quality
       Unf	Unfinshed
       NA	No Basement

**BsmtFinSF2**: Type 2 finished square feet

**BsmtUnfSF**: Unfinished square feet of basement area

**TotalBsmtSF**: Total square feet of basement area

**Heating**: Type of heating

       Floor	Floor Furnace
       GasA	Gas forced warm air furnace
       GasW	Gas hot water or steam heat
       Grav	Gravity furnace
       OthW	Hot water or steam heat other than gas
       Wall	Wall furnace

**HeatingQC**: Heating quality and condition

       Ex	Excellent
       Gd	Good
       TA	Average/Typical
       Fa	Fair
       Po	Poor

**CentralAir**: Central air conditioning

       N	No
       Y	Yes

**Electrical**: Electrical system

       SBrkr	Standard Circuit Breakers & Romex
       FuseA	Fuse Box over 60 AMP and all Romex wiring (Average)
       FuseF	60 AMP Fuse Box and mostly Romex wiring (Fair)
       FuseP	60 AMP Fuse Box and mostly knob & tube wiring (poor)
       Mix	Mixed

**1stFlrSF**: First Floor square feet

**2ndFlrSF**: Second floor square feet

**LowQualFinS**: Low quality finished square feet (all floors)

**GrLivArea**: Above grade (ground) living area square feet

**BsmtFullBath**: Basement full bathrooms

**BsmtHalfBath**: Basement half bathrooms

**FullBath**: Full bathrooms above grade

**HalfBath**: Half baths above grade

**Bedroom**: Bedrooms above grade (does NOT include basement bedrooms)

**Kitchen**: Kitchens above grade

**KitchenQual**: Kitchen quality

       Ex	Excellent
       Gd	Good
       TA	Typical/Average
       Fa	Fair
       Po	Poor

**TotRmsAbvGrd**: Total rooms above grade (does not include bathrooms)

**Functional**: Home functionality (Assume typical unless deductions are warranted)

       Typ	Typical Functionality
       Min1	Minor Deductions 1
       Min2	Minor Deductions 2
       Mod	Moderate Deductions
       Maj1	Major Deductions 1
       Maj2	Major Deductions 2
       Sev	Severely Damaged
       Sal	Salvage only

**Fireplaces**: Number of fireplaces

**FireplaceQu**: Fireplace quality

       Ex	Excellent - Exceptional Masonry Fireplace
       Gd	Good - Masonry Fireplace in main level
       TA	Average - Prefabricated Fireplace in main living area or Masonry Fireplace in basement
       Fa	Fair - Prefabricated Fireplace in basement
       Po	Poor - Ben Franklin Stove
       NA	No Fireplace

**GarageType:** Garage location

       2Types	More than one type of garage
       Attchd	Attached to home
       Basment	Basement Garage
       BuiltIn	Built-In (Garage part of house - typically has room above garage)
       CarPort	Car Port
       Detchd	Detached from home
       NA	No Garage

**GarageYrBlt**: Year garage was built

**GarageFinish**: Interior finish of the garage

       Fin	Finished
       RFn	Rough Finished
       Unf	Unfinished
       NA	No Garage

**GarageCars**: Size of garage in car capacity

**GarageArea**: Size of garage in square feet

**GarageQual**: Garage quality

       Ex	Excellent
       Gd	Good
       TA	Typical/Average
       Fa	Fair
       Po	Poor
       NA	No Garage

**GarageCond**: Garage condition

       Ex	Excellent
       Gd	Good
       TA	Typical/Average
       Fa	Fair
       Po	Poor
       NA	No Garage

**PavedDrive**: Paved driveway

       Y	Paved
       P	Partial Pavement
       N	Dirt/Gravel

**WoodDeckSF**: Wood deck area in square feet

**OpenPorchSF**: Open porch area in square feet

**EnclosedPorch**: Enclosed porch area in square feet

**3SsnPorch**: Three season porch area in square feet

**ScreenPorch**: Screen porch area in square feet

**PoolArea**: Pool area in square feet

**PoolQC**: Pool quality

       Ex	Excellent
       Gd	Good
       TA	Average/Typical
       Fa	Fair
       NA	No Pool

**Fence**: Fence quality

       GdPrv	Good Privacy
       MnPrv	Minimum Privacy
       GdWo	Good Wood
       MnWw	Minimum Wood/Wire
       NA	No Fence

***MiscFeature**: Miscellaneous feature not covered in other categories

       Elev	Elevator
       Gar2	2nd Garage (if not described in garage section)
       Othr	Other
       Shed	Shed (over 100 SF)
       TenC	Tennis Court
       NA	None

**MiscVal**: $Value of miscellaneous feature

**MoSold**: Month Sold (MM)

**YrSold**: Year Sold (YYYY)

**SaleType**: Type of sale

       WD 	Warranty Deed - Conventional
       CWD	Warranty Deed - Cash
       VWD	Warranty Deed - VA Loan
       New	Home just constructed and sold
       COD	Court Officer Deed/Estate
       Con	Contract 15% Down payment regular terms
       ConLw	Contract Low Down payment and low interest
       ConLI	Contract Low Interest
       ConLD	Contract Low Down
       Oth	Other

**SaleCondition**: Condition of sale

       Normal	Normal Sale
       Abnorml	Abnormal Sale -  trade, foreclosure, short sale
       AdjLand	Adjoining Land Purchase
       Alloca	Allocation - two linked properties with separate deeds, typically condo with a garage unit
       Family	Sale between family members
       Partial	Home was not completed when last assessed (associated with New Homes)

## Table of Content

1. **[Import Libraries](#import_lib)**
2. **[Set Options](#set_options)**
3. **[Read Data](#RD)**
4. **[Data Analysis and Preparation](#data_preparation)**
    - 4.1 - **[Data Type](#Data_Types)**
    - 4.2 - **[Check for missing values](#Summary_Statistics)**
    - 4.3- **[Handling missing values](#distribution_variables)**
    - 4.4 - **[Statistical Summary](#correlation)**
    - 4.5 - **[Cleaning test data](#correlation)**     
5. **[EDA](#LogisticReg)**
6. **[One Hot Encoding of Categorical data](#conclusion)**
7. **[Splitting the data](#conclusion)**
8. **[Model Trainig](#conclusion)**
    - 8.1 - **[Linear Regression](#Data_Types)**
    - 8.2 - **[Decision Tree Regressor](#Data_Types)**
    - 8.3 - **[Xgboost](#Data_Types)**
        - 8.3.1 - **[Hyper parameter optimization](#Data_Types)**
9. **[Prediction](#conclusion)**
10. **[Deployment](#conclusion)**

<a id='import_lib'></a>
# 1. Import Libraries
"""

# 'Pandas' is used for data manipulation and analysis
import pandas as pd
#fghy
# 'Numpy' is used for mathematical operations on large, multi-dimensional arrays and matrices
import numpy as np

# 'Matplotlib' is a data visualization library for 2D and 3D plots, built on numpy
import matplotlib.pyplot as plt

# 'Seaborn' is based on matplotlib; used for plotting statistical graphics
import seaborn as sns

# import various functions to perform regression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression
import xgboost
from sklearn.model_selection import RandomizedSearchCV
from sklearn.tree import DecisionTreeRegressor

"""<a id='set_options'></a>
# 2. Set Options
"""

# To show the all columns
pd.set_option("display.max_columns", 2000)

# To show all rows
pd.set_option("display.max_rows", 250)

"""<a id='RD'></a>
# 3. Read Data
"""

# read the csv data file
train_data=pd.read_csv('train.csv')

# display the top 5 rows of the dataframe
train_data.head()

"""#### Dimensions of the data"""

train_data.shape

"""<a id='data_preparation'></a>
# 4. Data Analysis and Preparation

<a id='Data_Understanding'></a>
## 4.1 Understand the Dataset

<a id='Data_Types'></a>
### 4.1.1 Data Type
The main data types in Pandas dataframes are the object, float, int64, bool, and datetime64. To understand each attribute of our data, it is always good for us to know the data type of each column.
"""

# 'dtypes' gives the data type for each column
train_data.dtypes

"""<a id='Check for missing Values'></a>
### 4.1.2 Check for missing Valuee

"""

# get the count of missing values
missing_values =train_data.isnull().sum()

# print the count of missing values
print(missing_values)

"""<a id='Check for missing Values'></a>




### 4.1.3 Handling missing Value
"""

train_data['LotFrontage']=train_data['LotFrontage'].fillna(train_data['LotFrontage'].mean())
train_data['Alley']=train_data['Alley'].fillna(train_data['Alley'].mode()[0])
train_data['BsmtCond']=train_data['BsmtCond'].fillna(train_data['BsmtCond'].mode()[0])
train_data['BsmtQual']=train_data['BsmtQual'].fillna(train_data['BsmtQual'].mode()[0])
train_data['FireplaceQu']=train_data['FireplaceQu'].fillna(train_data['FireplaceQu'].mode()[0])
train_data['GarageType']=train_data['GarageType'].fillna(train_data['GarageType'].mode()[0])
train_data.drop(['GarageYrBlt'],axis=1,inplace=True)
train_data['GarageFinish']=train_data['GarageFinish'].fillna(train_data['GarageFinish'].mode()[0])
train_data['GarageQual']=train_data['GarageQual'].fillna(train_data['GarageQual'].mode()[0])
train_data['GarageCond']=train_data['GarageCond'].fillna(train_data['GarageCond'].mode()[0])
train_data['PoolQC']=train_data['PoolQC'].fillna(train_data['PoolQC'].mode()[0])
train_data['Fence']=train_data['Fence'].fillna(train_data['Fence'].mode()[0])
train_data['MiscFeature']=train_data['MiscFeature'].fillna(train_data['MiscFeature'].mode()[0])
train_data.drop(['Id'],axis=1,inplace=True)
train_data['MasVnrType']=train_data['MasVnrType'].fillna(train_data['MasVnrType'].mode()[0])
train_data['MasVnrArea']=train_data['MasVnrArea'].fillna(train_data['MasVnrArea'].mode()[0])
train_data['BsmtExposure']=train_data['BsmtExposure'].fillna(train_data['BsmtExposure'].mode()[0])
train_data['BsmtFinType2']=train_data['BsmtFinType2'].fillna(train_data['BsmtFinType2'].mode()[0])

train_data.isna().sum()

#remove the rows which has a null value
train_data.dropna(inplace=True)

#gives total number of null values in each columns
train_data.isna().sum()

train_data.shape

"""<a id='Check for missing Values'></a>
### 4.1.4 Statistical Summary
"""

# data frame with numerical features
train_data.describe()

"""<a id='Check for missing Values'></a>
### 4.1.5 Cleaning of test data
"""

test_data=pd.read_csv('test.csv')

test_data.shape

test_data.isnull().sum()

test_data['LotFrontage']=test_data['LotFrontage'].fillna(test_data['LotFrontage'].mean())
test_data['MSZoning']=test_data['MSZoning'].fillna(test_data['MSZoning'].mode()[0])
test_data['Alley']=test_data['Alley'].fillna(test_data['Alley'].mode()[0])
test_data['BsmtCond']=test_data['BsmtCond'].fillna(test_data['BsmtCond'].mode()[0])
test_data['BsmtQual']=test_data['BsmtQual'].fillna(test_data['BsmtQual'].mode()[0])
test_data['FireplaceQu']=test_data['FireplaceQu'].fillna(test_data['FireplaceQu'].mode()[0])
test_data['GarageType']=test_data['GarageType'].fillna(test_data['GarageType'].mode()[0])
test_data.drop(['GarageYrBlt'],axis=1,inplace=True)
test_data['GarageFinish']=test_data['GarageFinish'].fillna(test_data['GarageFinish'].mode()[0])
test_data['GarageQual']=test_data['GarageQual'].fillna(test_data['GarageQual'].mode()[0])
test_data['GarageCond']=test_data['GarageCond'].fillna(test_data['GarageCond'].mode()[0])
test_data['PoolQC']=test_data['PoolQC'].fillna(test_data['PoolQC'].mode()[0])
test_data['Fence']=test_data['Fence'].fillna(test_data['Fence'].mode()[0])
test_data['MiscFeature']=test_data['MiscFeature'].fillna(test_data['MiscFeature'].mode()[0])
test_data.drop(['Id'],axis=1,inplace=True)
test_data['MasVnrType']=test_data['MasVnrType'].fillna(test_data['MasVnrType'].mode()[0])
test_data['MasVnrArea']=test_data['MasVnrArea'].fillna(test_data['MasVnrArea'].mode()[0])
test_data['BsmtExposure']=test_data['BsmtExposure'].fillna(test_data['BsmtExposure'].mode()[0])
test_data['BsmtFinType2']=test_data['BsmtFinType2'].fillna(test_data['BsmtFinType2'].mode()[0])
test_data['Utilities']=test_data['Utilities'].fillna(test_data['Utilities'].mode()[0])
test_data['Exterior1st']=test_data['Exterior1st'].fillna(test_data['Exterior1st'].mode()[0])
test_data['Exterior2nd']=test_data['Exterior2nd'].fillna(test_data['Exterior2nd'].mode()[0])
test_data['BsmtFinType1']=test_data['BsmtFinType1'].fillna(test_data['BsmtFinType1'].mode()[0])
test_data['BsmtFinSF1']=test_data['BsmtFinSF1'].fillna(test_data['BsmtFinSF1'].mean())
test_data['BsmtFinSF2']=test_data['BsmtFinSF2'].fillna(test_data['BsmtFinSF2'].mean())
test_data['BsmtUnfSF']=test_data['BsmtUnfSF'].fillna(test_data['BsmtUnfSF'].mean())
test_data['TotalBsmtSF']=test_data['TotalBsmtSF'].fillna(test_data['TotalBsmtSF'].mean())
test_data['BsmtFullBath']=test_data['BsmtFullBath'].fillna(test_data['BsmtFullBath'].mode()[0])
test_data['BsmtHalfBath']=test_data['BsmtHalfBath'].fillna(test_data['BsmtHalfBath'].mode()[0])
test_data['KitchenQual']=test_data['KitchenQual'].fillna(test_data['KitchenQual'].mode()[0])
test_data['Functional']=test_data['Functional'].fillna(test_data['Functional'].mode()[0])
test_data['GarageCars']=test_data['GarageCars'].fillna(test_data['GarageCars'].mean())
test_data['GarageArea']=test_data['GarageArea'].fillna(test_data['GarageArea'].mean())
test_data['SaleType']=test_data['SaleType'].fillna(test_data['SaleType'].mode()[0])

test_data.shape

test_data.isna().sum()

"""<a id='RD'></a>
# 5. EDA
"""

corr_matrix = train_data.corr()
high_corr_features = corr_matrix[abs(corr_matrix['SalePrice']) > 0.5].index

# Select the relevant columns from the DataFrame
high_corr_df = train_data[high_corr_features]

# Create a heatmap of the high correlation features
plt.figure(figsize=(12, 8))
sns.heatmap(high_corr_df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.xlabel("Correlation Heatmap of Features with Correlation > 0.5")
plt.show()

plt.figure(figsize=(8, 6))
sns.histplot(train_data['SalePrice'], kde=True)
plt.xlabel('Distribution of SalePrice')
plt.show()

sns.pairplot(train_data, vars=['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'SalePrice'])

"""<a id="Label_Encoding_of_Categorical_Data"> </a>
## 6. One Hot Encoding of Categorical Data
"""

columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',
         'Condition2','BldgType','Condition1','HouseStyle','SaleType',
        'SaleCondition','ExterCond',
         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',
        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',
         'CentralAir',
         'Electrical','KitchenQual','Functional',
         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive','Alley','PoolQC','Fence','MiscFeature']

len(columns)

def category_onehot_multcols(multcolumns):
    df_final=final_df
    i=0
    for fields in multcolumns:

        print(fields)
        df1=pd.get_dummies(final_df[fields],drop_first=True)

        final_df.drop([fields],axis=1,inplace=True)
        if i==0:
            df_final=df1.copy()
        else:

            df_final=pd.concat([df_final,df1],axis=1)
        i=i+1


    df_final=pd.concat([final_df,df_final],axis=1)

    return df_final

#combine the train and test data
final_df=pd.concat([train_data,test_data],axis=0)

#pass the final_df with one hot encoder function
final_df=category_onehot_multcols(columns)

final_df.shape

#removing the duplicated features from the dataset
final_df =final_df.loc[:,~final_df.columns.duplicated()]

final_df.shape

"""<a id="Label_Encoding_of_Categorical_Data"> </a>
## 7. Splitting the data
"""

df_Train=final_df.iloc[:1422,:]
df_Test=final_df.iloc[1422:,:]

df_Test.drop(['SalePrice'],axis=1,inplace=True)

x=df_Train.drop(columns='SalePrice',axis=1)

y=df_Train['SalePrice']

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

"""<a id="Label_Encoding_of_Categorical_Data"> </a>
## 8. Model Training

<a id='Check for missing Values'></a>
### 8.1  Linear Regression
"""

model_1=LinearRegression()

model_1.fit(x_train,y_train)

ypred_1=model_1.predict(x_test)

model_1.score(x_test,y_test)

rmse_linear_regression=np.sqrt(mean_squared_error(y_test,ypred_1))

# Scatter plot of actual vs. predicted values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, ypred_1)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Linear Regression: Actual vs. Predicted')
plt.show()

"""<a id='Check for missing Values'></a>
### 8.2  Decision Tree Regressor
"""

model_3=DecisionTreeRegressor()

model_3.fit(x_train,y_train)

ypred_3=model_3.predict(x_test)

model_3.score(x_test,y_test)

rmse_decision_tree=np.sqrt(mean_squared_error(y_test,ypred_3))

# Scatter plot of actual vs. predicted values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, ypred_3)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Decision Tree Regressor: Actual vs. Predicted')
plt.show()

"""<a id='Check for missing Values'></a>
### 8.3  Xgboost
"""

regressor=xgboost.XGBRegressor()

regressor.fit(x_train,y_train)

ypred_4=regressor.predict(x_test)

regressor.score(x_test,y_test)

#root mean square error
rmse_xgboost=np.sqrt(mean_squared_error(y_test,ypred_4))

# Scatter plot of actual vs. predicted values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, ypred_4)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('XGBoost: Actual vs. Predicted')
plt.show()

import matplotlib.pyplot as plt

# List of model names
models = ['Linear Regression', 'Decision Tree', 'XGBoost']

# List of corresponding RMSE values
rmse_values = [rmse_linear_regression, rmse_decision_tree, rmse_xgboost]  # Replace with actual RMSE values

# Create a bar chart with reduced color density
color_palette = ['#88CCEE', '#CC6677', '#DDCC77']  # Use a lighter color palette

plt.figure(figsize=(10, 6))
plt.bar(models, rmse_values, color=color_palette)
plt.xlabel('RMSE Comparison for Different Models')
plt.ylabel('RMSE')
plt.show()

"""<a id='Check for missing Values'></a>
## 8.3.1 Hyper Parameter optimization
"""

## Hyper Parameter Optimization
from sklearn.model_selection import RandomizedSearchCV
n_estimators = [100, 500, 900, 1100, 1500]
max_depth = [2, 3, 5, 10, 15]
booster=['gbtree','gblinear']
learning_rate=[0.05,0.1,0.15,0.20]
min_child_weight=[1,2,3,4]
base_score=[0.25,0.5,0.75,1]

# Define the grid of hyperparameters to search
hyperparameter_grid = {
    'n_estimators': n_estimators,
    'max_depth':max_depth,
    'learning_rate':learning_rate,
    'min_child_weight':min_child_weight,
    'booster':booster,
    'base_score':base_score
    }

random_cv = RandomizedSearchCV(estimator=regressor,
            param_distributions=hyperparameter_grid,
            cv=5, n_iter=50,
            scoring = 'neg_mean_absolute_error',n_jobs = 4,
            verbose = 5,
            return_train_score = True,
            random_state=42)

random_cv.fit(x_train,y_train)

random_cv.best_estimator_

regressor = xgboost.XGBRegressor(base_score=0.25, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=0.1, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=2, max_leaves=None,
             min_child_weight=1,  monotone_constraints=None,
             multi_strategy=None, n_estimators=900, n_jobs=None,
             num_parallel_tree=None, random_state=None)

regressor.fit(x_train,y_train)
y_pred=regressor.predict(x_test)
print("score: ", str(regressor.score(x_test,y_test) ))
print("rmse: ", str(np.sqrt(mean_squared_error(y_test,y_pred))))

"""<a id="Label_Encoding_of_Categorical_Data"> </a>
## 9. Prediction
The prediction is for the test_data
"""

predictions=regressor.predict(df_Test)

prediction = pd.DataFrame(predictions)

prediction.to_csv('pred_test_data.csv')

prediction

"""<a id="Label_Encoding_of_Categorical_Data"> </a>
## 10. Deployment

"""

!pip install streamlit -q

# Commented out IPython magic to ensure Python compatibility.
# %%writefile web_page_xgboost_custom.py
# # Import necessary libraries
# import streamlit as st
# import pandas as pd
# import numpy as np
# from sklearn.preprocessing import OneHotEncoder
# import xgboost as xgb
# 
# def local_css(file_name):
#     with open(file_name) as f:
#         st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
# 
# # Local CSS sheet
# local_css("style.css")
# 
# # Function to preprocess data, train the model, and return predictions
# def train_and_predict(df, feature_values, encoder):
#     # Separate categorical and numeric columns
#     categorical_cols = df.select_dtypes(include=['object']).columns
#     numeric_cols = [col for col in df.columns if col not in categorical_cols and col != 'SalePrice']
# 
#     # Encode categorical features in the training data
#     X_categorical = encoder.transform(df[categorical_cols])
# 
#     # Combine encoded categorical features with numeric features
#     X = np.concatenate((X_categorical, df[numeric_cols].values), axis=1)
#     y = df['SalePrice'].values
# 
#     # Train an XGBoost model with custom hyperparameters
#     model = xgb.XGBRegressor(
#         n_estimators=900,
#         max_depth=2,
#         learning_rate=0.1,
#         base_score=0.25,
#         booster='gbtree',
#         enable_categorical=False,
#         eval_metric=None,
#         gamma=None,
#         min_child_weight=1,
#         random_state=None
#     )
#     model.fit(X, y)  # Use the entire dataset for training
# 
#     # Prepare the input feature values for prediction
#     input_categorical = encoder.transform(np.array([feature_values[column] for column in categorical_cols]).reshape(1, -1))
#     input_numeric = np.array([feature_values[column] for column in numeric_cols]).astype(float).reshape(1, -1)
# 
#     # Combine encoded categorical features with numeric features for prediction
#     input_features = np.concatenate((input_categorical, input_numeric), axis=1)
# 
#     # Predict the 'SalePrice' column using the provided feature values
#     predicted_value = model.predict(input_features)
# 
#     return predicted_value[0]
# 
# # Streamlit app
# st.title("House Price Prediction App")
# 
# # Upload a CSV file
# uploaded_file = st.file_uploader("Upload your CSV file", type=["csv"])
# 
# if uploaded_file is not None:
#     # Load the dataset
#     df = pd.read_csv(uploaded_file)
# 
#     st.subheader("DataFrame Preview")
#     st.write(df.head())
# 
#     # Exclude the 'SalePrice' column from the list of categorical and numeric columns
#     categorical_cols = df.select_dtypes(include=['object']).columns
#     numeric_cols = [col for col in df.columns if col not in categorical_cols and col != 'SalePrice']
# 
#     # Select the feature columns and input values manually
#     st.subheader("Manually Enter Feature Values")
#     feature_values = {}
# 
#     for column in categorical_cols:
#         if column != 'SalePrice':
#             feature_values[column] = st.selectbox(f"Select value for {column}", df[column].unique())
# 
#     for column in numeric_cols:
#         if column != 'SalePrice':
#             input_value = st.text_input(f"Enter value for {column}", "")
#             # Check for empty string or space and replace with a default value (e.g., 0)
#             input_value = input_value.strip()  # Remove leading/trailing spaces
#             input_value = input_value if input_value != "" else "0"  # Replace empty string with "0"
#             feature_values[column] = input_value
# 
#     # Create and fit the OneHotEncoder on the categorical columns
#     encoder = OneHotEncoder(sparse=False, drop='first')
#     encoder.fit(df[categorical_cols])
# 
#     if st.button("Predict"):
#         predicted_value = train_and_predict(df, feature_values, encoder)
# 
#         st.subheader("Predicted Value")
#         st.write(f"The predicted 'SalePrice' value for the provided feature values is: {predicted_value:.2f}")
#         st.success("Prediction made successfully!")
#

!streamlit run web_page_xgboost_custom.py & npx localtunnel --port 8501

